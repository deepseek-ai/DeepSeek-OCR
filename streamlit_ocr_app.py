"""
DeepSeek OCR - Streamlit Application
Aplica√ß√£o completa com upload de imagens e todos os recursos do DeepSeek OCR
"""

import streamlit as st
import torch
from transformers import AutoModel, AutoTokenizer
from PIL import Image
import os
import io
import json
from pathlib import Path
import tempfile
import time
import warnings

# Suprime avisos conhecidos do HuggingFace Transformers
# O aviso "model of type deepseek_vl_v2 to instantiate model of type DeepseekOCR"
# √© esperado e n√£o afeta o funcionamento do modelo
warnings.filterwarnings('ignore', message='.*deepseek_vl_v2.*')
warnings.filterwarnings('ignore', message='.*DeepseekOCR.*')
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="DeepSeek OCR",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #424242;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .result-box {
        background-color: #F5F5F5;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 4px solid #1E88E5;
    }
    .stButton > button {
        width: 100%;
        background-color: #1E88E5;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.markdown('<h1 class="main-header">üîç DeepSeek OCR Application</h1>', unsafe_allow_html=True)
st.markdown("### Upload de imagens e extra√ß√£o de texto com IA")

# Helper function para limpar cache corrompido
def clear_model_cache(model_name):
    """Limpa o cache do modelo corrompido"""
    from pathlib import Path
    import shutil

    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"

    if cache_dir.exists():
        # Encontra diret√≥rios do modelo
        model_dirs = list(cache_dir.glob("*deepseek*"))
        for model_dir in model_dirs:
            try:
                st.warning(f"üóëÔ∏è Removendo cache corrompido: {model_dir.name}")
                shutil.rmtree(model_dir)
                st.success(f"‚úÖ Cache removido: {model_dir.name}")
            except Exception as e:
                st.error(f"‚ùå Erro ao remover: {e}")
    return len(model_dirs) if cache_dir.exists() else 0

# Cache do modelo para n√£o recarregar a cada intera√ß√£o
@st.cache_resource
def load_model(force_download=False):
    """Carrega o modelo DeepSeek OCR"""
    with st.spinner("üîÑ Carregando modelo DeepSeek OCR... (isso pode levar alguns minutos)"):
        model_name = 'deepseek-ai/DeepSeek-OCR'

        # FOR√áA O USO DE CPU (configurado para esta atividade)
        device = "cpu"
        st.info("üñ•Ô∏è Usando CPU para processamento (configurado)")

        try:
            # Carrega tokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                trust_remote_code=True,
                force_download=force_download
            )

            # Tenta carregar modelo com safetensors
            st.info("üîÑ Carregando modelo para CPU...")
            try:
                model = AutoModel.from_pretrained(
                    model_name,
                    trust_remote_code=True,
                    use_safetensors=True,
                    torch_dtype=torch.float32,
                    force_download=force_download
                )
            except Exception as safetensor_error:
                error_msg = str(safetensor_error)

                # Detecta arquivo corrompido
                if "SafetensorError" in error_msg or "EOF while parsing" in error_msg or "invalid JSON" in error_msg:
                    st.error("‚ö†Ô∏è **Arquivo do modelo corrompido detectado!**")
                    st.warning("üîÑ Tentando limpar cache e baixar novamente...")

                    # Limpa cache
                    cleared = clear_model_cache(model_name)
                    if cleared > 0:
                        st.info(f"‚úÖ {cleared} cache(s) removido(s). Baixando modelo novamente...")

                        # Tenta baixar novamente
                        model = AutoModel.from_pretrained(
                            model_name,
                            trust_remote_code=True,
                            use_safetensors=True,
                            torch_dtype=torch.float32,
                            force_download=True
                        )
                    else:
                        st.error("‚ùå N√£o foi poss√≠vel limpar o cache automaticamente.")
                        st.info("üîÑ Tentando carregar sem safetensors...")

                        # Fallback: tenta sem safetensors
                        model = AutoModel.from_pretrained(
                            model_name,
                            trust_remote_code=True,
                            use_safetensors=False,
                            torch_dtype=torch.float32,
                            force_download=True
                        )
                else:
                    raise safetensor_error

            model = model.eval()
            st.success("‚úÖ Modelo carregado para CPU com sucesso!")

            return model, tokenizer, device

        except Exception as e:
            st.error(f"‚ùå Erro ao carregar modelo: {str(e)}")

            # Instru√ß√µes de recupera√ß√£o
            st.markdown("""
            ### üîß Como Resolver Manualmente

            **Op√ß√£o 1: Limpar Cache Manualmente (Recomendado)**

            No **Windows**:
            ```
            # Abra o PowerShell e execute:
            Remove-Item -Recurse -Force "$env:USERPROFILE\\.cache\\huggingface\\hub\\*deepseek*"
            ```

            Ou navegue at√©:
            ```
            C:\\Users\\<seu_usuario>\\.cache\\huggingface\\hub\\
            ```
            E delete todas as pastas que contenham "deepseek" no nome.

            **No Linux/Mac**:
            ```bash
            rm -rf ~/.cache/huggingface/hub/*deepseek*
            ```

            **Op√ß√£o 2: Usar Vari√°vel de Ambiente**

            Antes de executar o Streamlit:
            ```bash
            # Windows PowerShell
            $env:TRANSFORMERS_CACHE = "C:\\temp\\hf_cache"
            streamlit run streamlit_ocr_app.py

            # Linux/Mac
            export TRANSFORMERS_CACHE=/tmp/hf_cache
            streamlit run streamlit_ocr_app.py
            ```

            **Op√ß√£o 3: Reinstalar do Zero**
            ```bash
            pip uninstall transformers tokenizers -y
            pip install transformers>=4.46.3 tokenizers>=0.20.3
            ```

            Depois reinicie a aplica√ß√£o Streamlit.
            """)

            st.exception(e)
            return None, None, None

# Modos de resolu√ß√£o predefinidos
RESOLUTION_MODES = {
    "Tiny (512x512 - 64 tokens)": {
        "base_size": 512,
        "image_size": 512,
        "crop_mode": False,
        "description": "Mais r√°pido, menor qualidade. Ideal para testes."
    },
    "Small (640x640 - 100 tokens)": {
        "base_size": 640,
        "image_size": 640,
        "crop_mode": False,
        "description": "R√°pido com qualidade razo√°vel."
    },
    "Base (1024x1024 - 256 tokens)": {
        "base_size": 1024,
        "image_size": 1024,
        "crop_mode": False,
        "description": "Balanceado entre velocidade e qualidade."
    },
    "Large (1280x1280 - 400 tokens)": {
        "base_size": 1280,
        "image_size": 1280,
        "crop_mode": False,
        "description": "Alta qualidade, mais lento."
    },
    "Gundam (Din√¢mico 1024 + 640)": {
        "base_size": 1024,
        "image_size": 640,
        "crop_mode": True,
        "description": "Resolu√ß√£o din√¢mica adaptativa (RECOMENDADO)."
    },
    "Custom (Personalizado)": {
        "base_size": 1024,
        "image_size": 640,
        "crop_mode": True,
        "description": "Configure manualmente os par√¢metros."
    }
}

# Prompts predefinidos
PREDEFINED_PROMPTS = {
    "Documento para Markdown (com layout)": "<image>\n<|grounding|>Convert the document to markdown.",
    "OCR de Imagem Geral": "<image>\n<|grounding|>OCR this image.",
    "OCR Livre (sem layout)": "<image>\nFree OCR.",
    "Parse de Figura": "<image>\nParse the figure.",
    "Descri√ß√£o Detalhada": "<image>\nDescribe this image in detail.",
    "Localiza√ß√£o de Texto": "<image>\nLocate <|ref|>{text}<|/ref|> in the image.",
    "Custom (Personalizado)": ""
}

# Sidebar - Configura√ß√µes
st.sidebar.header("‚öôÔ∏è Configura√ß√µes")

# Sele√ß√£o de modo de resolu√ß√£o
st.sidebar.subheader("üìê Modo de Resolu√ß√£o")
resolution_mode = st.sidebar.selectbox(
    "Escolha o modo:",
    list(RESOLUTION_MODES.keys()),
    index=4  # Default: Gundam
)

# Mostra descri√ß√£o do modo
st.sidebar.info(RESOLUTION_MODES[resolution_mode]["description"])

# Par√¢metros configur√°veis
if resolution_mode == "Custom (Personalizado)":
    st.sidebar.subheader("üîß Par√¢metros Customizados")

    base_size = st.sidebar.select_slider(
        "Base Size (resolu√ß√£o global):",
        options=[512, 640, 1024, 1280],
        value=1024
    )

    image_size = st.sidebar.select_slider(
        "Image Size (resolu√ß√£o local):",
        options=[512, 640, 1024, 1280],
        value=640
    )

    crop_mode = st.sidebar.checkbox(
        "Crop Mode (divis√£o din√¢mica)",
        value=True
    )

    if crop_mode:
        min_crops = st.sidebar.slider("Min Crops:", 1, 9, 2)
        max_crops = st.sidebar.slider("Max Crops:", min_crops, 9, 6)
    else:
        min_crops, max_crops = 2, 6

else:
    base_size = RESOLUTION_MODES[resolution_mode]["base_size"]
    image_size = RESOLUTION_MODES[resolution_mode]["image_size"]
    crop_mode = RESOLUTION_MODES[resolution_mode]["crop_mode"]
    min_crops, max_crops = 2, 6

# Configura√ß√µes adicionais
st.sidebar.subheader("üéõÔ∏è Configura√ß√µes Avan√ßadas")

test_compress = st.sidebar.checkbox(
    "Test Compress (compress√£o de tokens)",
    value=True,
    help="Ativa compress√£o de tokens de vis√£o para economizar mem√≥ria"
)

save_results = st.sidebar.checkbox(
    "Salvar Resultados",
    value=False,
    help="Salva os resultados em arquivos"
)

# Mostrar informa√ß√µes do sistema
st.sidebar.subheader("üíª Informa√ß√µes do Sistema")
st.sidebar.info("**Dispositivo:** üñ•Ô∏è CPU (For√ßado)")
st.sidebar.warning("‚ö†Ô∏è Configurado para usar CPU apenas\n\nO processamento ser√° mais lento, mas funcional.")

# √Årea principal
col1, col2 = st.columns([1, 1])

with col1:
    st.markdown('<div class="sub-header">üì§ Upload de Imagem</div>', unsafe_allow_html=True)

    uploaded_file = st.file_uploader(
        "Escolha uma imagem (JPG, PNG, JPEG):",
        type=["jpg", "jpeg", "png"],
        help="Fa√ßa upload de uma imagem para processar com OCR"
    )

    if uploaded_file is not None:
        # Exibe a imagem
        image = Image.open(uploaded_file).convert('RGB')
        st.image(image, caption="Imagem carregada", width='stretch')

        # Informa√ß√µes da imagem
        width, height = image.size
        st.info(f"**Dimens√µes:** {width}x{height} pixels | **Formato:** {image.format}")

with col2:
    st.markdown('<div class="sub-header">üí¨ Configura√ß√£o do Prompt</div>', unsafe_allow_html=True)

    prompt_choice = st.selectbox(
        "Escolha um prompt predefinido:",
        list(PREDEFINED_PROMPTS.keys())
    )

    if prompt_choice == "Custom (Personalizado)":
        prompt_text = st.text_area(
            "Digite seu prompt personalizado:",
            value="<image>\n<|grounding|>Convert the document to markdown.",
            height=150,
            help="Use <image> para posi√ß√£o da imagem. Use <|grounding|> para incluir informa√ß√µes de layout."
        )
    elif prompt_choice == "Localiza√ß√£o de Texto":
        search_text = st.text_input("Digite o texto a ser localizado:", value="texto")
        prompt_text = PREDEFINED_PROMPTS[prompt_choice].replace("{text}", search_text)
    else:
        prompt_text = PREDEFINED_PROMPTS[prompt_choice]
        st.code(prompt_text, language="text")

    # Informa√ß√µes sobre os prompts
    st.markdown("""
    <div class="info-box">
    <strong>üí° Dicas de Prompts:</strong>
    <ul>
        <li><code>&lt;image&gt;</code> - Posi√ß√£o da imagem no prompt</li>
        <li><code>&lt;|grounding|&gt;</code> - Inclui informa√ß√µes de layout e posicionamento</li>
        <li><code>&lt;|ref|&gt;texto&lt;|/ref|&gt;</code> - Localiza texto espec√≠fico na imagem</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)

# Bot√£o de processamento
st.markdown("---")
process_button = st.button("üöÄ Processar Imagem com OCR", width='stretch')

if process_button and uploaded_file is not None:

    # Carrega o modelo
    model, tokenizer, device = load_model()

    if model is None or tokenizer is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar o modelo. Verifique a instala√ß√£o.")
        st.stop()

    # Cria diret√≥rio tempor√°rio para resultados
    with tempfile.TemporaryDirectory() as temp_dir:

        # Salva imagem tempor√°ria
        temp_image_path = os.path.join(temp_dir, "temp_image.jpg")
        image.save(temp_image_path)

        # Mostra configura√ß√µes sendo usadas
        with st.expander("üîç Ver Configura√ß√µes de Processamento", expanded=False):
            config_info = {
                "Modo": resolution_mode,
                "Base Size": base_size,
                "Image Size": image_size,
                "Crop Mode": crop_mode,
                "Min Crops": min_crops if crop_mode else "N/A",
                "Max Crops": max_crops if crop_mode else "N/A",
                "Test Compress": test_compress,
                "Prompt": prompt_text,
                "Device": device_info
            }
            st.json(config_info)

        # Processamento
        try:
            with st.spinner("üîÑ Processando imagem com DeepSeek OCR..."):
                start_time = time.time()

                # Chama o modelo
                result = model.infer(
                    tokenizer=tokenizer,
                    prompt=prompt_text,
                    image_file=temp_image_path,
                    output_path=temp_dir,
                    base_size=base_size,
                    image_size=image_size,
                    crop_mode=crop_mode,
                    test_compress=test_compress,
                    save_results=save_results
                )

                end_time = time.time()
                processing_time = end_time - start_time

            # Mostra resultados
            st.success(f"‚úÖ Processamento conclu√≠do em {processing_time:.2f} segundos!")

            # Resultado principal
            st.markdown('<div class="sub-header">üìù Resultado do OCR</div>', unsafe_allow_html=True)

            # Cria tabs para diferentes visualiza√ß√µes
            tab1, tab2, tab3 = st.tabs(["üìÑ Texto", "üìã Markdown", "üî¢ Estat√≠sticas"])

            with tab1:
                st.markdown('<div class="result-box">', unsafe_allow_html=True)
                st.text_area(
                    "Texto extra√≠do:",
                    value=result,
                    height=400,
                    label_visibility="collapsed"
                )
                st.markdown('</div>', unsafe_allow_html=True)

                # Bot√£o de download
                st.download_button(
                    label="üíæ Download Texto (.txt)",
                    data=result,
                    file_name="ocr_result.txt",
                    mime="text/plain"
                )

            with tab2:
                st.markdown(result)

                # Bot√£o de download markdown
                st.download_button(
                    label="üíæ Download Markdown (.md)",
                    data=result,
                    file_name="ocr_result.md",
                    mime="text/markdown"
                )

            with tab3:
                # Estat√≠sticas do resultado
                stats = {
                    "Total de caracteres": len(result),
                    "Total de palavras": len(result.split()),
                    "Total de linhas": len(result.split('\n')),
                    "Tempo de processamento": f"{processing_time:.2f}s",
                    "Caracteres/segundo": f"{len(result)/processing_time:.0f}"
                }

                # Mostra estat√≠sticas em colunas
                stat_cols = st.columns(3)
                for idx, (key, value) in enumerate(stats.items()):
                    with stat_cols[idx % 3]:
                        st.metric(key, value)

                # An√°lise do texto
                st.subheader("üìä An√°lise do Texto")

                # Contagem de tipos de caracteres
                num_digits = sum(c.isdigit() for c in result)
                num_alpha = sum(c.isalpha() for c in result)
                num_spaces = sum(c.isspace() for c in result)
                num_special = len(result) - num_digits - num_alpha - num_spaces

                analysis_data = {
                    "Letras": num_alpha,
                    "N√∫meros": num_digits,
                    "Espa√ßos": num_spaces,
                    "Especiais": num_special
                }

                st.bar_chart(analysis_data)

            # Se salvar resultados estiver ativado, mostra informa√ß√£o
            if save_results:
                st.info(f"üìÅ Resultados salvos em: {temp_dir}")

        except Exception as e:
            st.error(f"‚ùå Erro durante o processamento: {str(e)}")
            st.exception(e)

elif process_button and uploaded_file is None:
    st.warning("‚ö†Ô∏è Por favor, fa√ßa upload de uma imagem primeiro!")

# Rodap√© com informa√ß√µes
st.markdown("---")
st.markdown("""
### üìö Sobre o DeepSeek OCR

DeepSeek OCR √© um modelo avan√ßado de reconhecimento √≥ptico de caracteres que combina:
- **SAM ViT-B**: Segment Anything Model para features locais
- **CLIP-L**: Semantic features globais
- **DeepSeek V2/V3**: LLM backbone para compreens√£o contextual

**Recursos:**
- ‚úÖ Multi-resolu√ß√£o adaptativa
- ‚úÖ Suporte a layouts complexos
- ‚úÖ Extra√ß√£o de tabelas e figuras
- ‚úÖ Convers√£o para Markdown
- ‚úÖ Grounding e localiza√ß√£o de texto

**Transforma√ß√µes de Imagem:**
- `ImageTransform`: Normaliza√ß√£o e convers√£o para tensor
- `dynamic_preprocess`: Redimensionamento e divis√£o em tiles
- `count_tiles`: Layout otimizado baseado em aspect ratio

---
üîó **Modelo:** [deepseek-ai/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
""")

# Exemplos de uso
with st.expander("üí° Exemplos de Uso"):
    st.markdown("""
    ### Casos de Uso Comuns

    **1. Documentos Escaneados:**
    - Modo: Gundam ou Large
    - Prompt: "Convert the document to markdown"

    **2. Screenshots de C√≥digo:**
    - Modo: Base ou Large
    - Prompt: "OCR this image"

    **3. Tabelas Complexas:**
    - Modo: Gundam
    - Prompt: "Convert the document to markdown"

    **4. Imagens com Texto Pequeno:**
    - Modo: Large
    - Prompt: "OCR this image"

    **5. Figuras e Diagramas:**
    - Modo: Gundam
    - Prompt: "Parse the figure"
    """)

# Informa√ß√µes t√©cnicas
with st.expander("üîß Informa√ß√µes T√©cnicas sobre Transforms"):
    st.markdown("""
    ### Transforms Utilizados no DeepSeek OCR

    **1. ImageTransform**
    ```python
    class ImageTransform:
        def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), normalize=True):
            # Aplica ToTensor() e Normalize
            # Converte PIL Image para tensor PyTorch
            # Normaliza valores de pixel para [-1, 1]
    ```

    **2. Dynamic Preprocessing**
    ```python
    def dynamic_preprocess(image, base_size, image_size, crop_mode):
        # Redimensiona imagem mantendo aspect ratio
        # Divide em tiles se crop_mode=True
        # Retorna global view + local views
    ```

    **3. Count Tiles**
    ```python
    def count_tiles(h, w, min_num, max_num):
        # Calcula grid layout otimizado
        # Baseado no aspect ratio da imagem
        # Retorna n√∫mero de tiles em cada dimens√£o
    ```

    **4. Aspect Ratio Matching**
    ```python
    def find_closest_aspect_ratio(aspect_ratio, target_ratios):
        # Encontra melhor correspond√™ncia de aspect ratio
        # Usado para dynamic cropping
    ```

    **Pipeline Completo:**
    1. Load image ‚Üí PIL Image RGB
    2. Dynamic preprocessing ‚Üí Resize + Crop
    3. ImageTransform ‚Üí Tensor + Normalize
    4. Pad ‚Üí Quadrado com tamanho alvo
    5. Feature extraction ‚Üí SAM + CLIP
    6. Projection ‚Üí Embedding space
    7. LLM generation ‚Üí Texto final
    """)

# Notas t√©cnicas e avisos
with st.expander("‚ö†Ô∏è Notas T√©cnicas e Avisos Conhecidos"):
    st.markdown("""
    ### Avisos Conhecidos do HuggingFace Transformers

    **Aviso: "model of type deepseek_vl_v2 to instantiate model of type DeepseekOCR"**

    Este aviso pode aparecer no console/terminal ao carregar o modelo:

    ```
    You are using a model of type deepseek_vl_v2 to instantiate a model
    of type DeepseekOCR. This is not supported for all configurations of
    models and can yield errors.
    ```

    **Por que isso acontece?**
    - O arquivo `config.json` do modelo no HuggingFace define o tipo como `deepseek_vl_v2`
    - O c√≥digo custom Python usa a classe `DeepseekOCR`
    - O HuggingFace Transformers detecta essa diferen√ßa e emite um aviso

    **√â um problema?**
    - ‚úÖ **N√ÉO** - Este √© apenas um aviso informativo
    - ‚úÖ O modelo carrega e funciona perfeitamente
    - ‚úÖ A aplica√ß√£o suprime automaticamente este aviso
    - ‚úÖ √â esperado quando se usa `trust_remote_code=True`

    **Por que usar trust_remote_code=True?**
    - O DeepSeek-OCR usa c√≥digo custom n√£o dispon√≠vel no Transformers padr√£o
    - Permite carregar arquiteturas de modelo personalizadas do HuggingFace
    - √â seguro para modelos oficiais como deepseek-ai/DeepSeek-OCR

    ---

    ### Erro: SafetensorError (Arquivo Corrompido)

    **Sintoma:**
    ```
    SafetensorError: Error while deserializing header: invalid JSON in header:
    EOF while parsing a value at line 1 column 0
    ```

    **Causa:**
    - Arquivo do modelo corrompido no cache do HuggingFace
    - Download interrompido ou incompleto
    - Problema de conex√£o durante o download inicial

    **‚úÖ Solu√ß√£o Autom√°tica (Implementada):**

    A aplica√ß√£o detecta e resolve automaticamente:
    1. ‚úÖ Identifica erro SafetensorError
    2. ‚úÖ Remove cache corrompido automaticamente
    3. ‚úÖ Baixa modelo novamente (completo)
    4. ‚úÖ Fallback para download sem safetensors se necess√°rio

    **üîß Solu√ß√£o Manual (Windows):**

    Se a autom√°tica falhar, abra PowerShell:
    ```powershell
    Remove-Item -Recurse -Force "$env:USERPROFILE\\.cache\\huggingface\\hub\\*deepseek*"
    ```

    Ou navegue at√©:
    `C:\\Users\\<usuario>\\.cache\\huggingface\\hub\\`
    e delete pastas com "deepseek" no nome.

    **üîß Solu√ß√£o Manual (Linux/Mac):**
    ```bash
    rm -rf ~/.cache/huggingface/hub/*deepseek*
    ```

    **üí° Preven√ß√£o:**
    - Mantenha conex√£o est√°vel durante download
    - Aguarde download completo (~10GB)
    - N√£o interrompa processo de carregamento

    ---

    ### Configura√ß√£o CPU vs GPU

    **Esta aplica√ß√£o est√° configurada para usar CPU apenas:**
    - ‚úÖ Compat√≠vel com qualquer sistema (n√£o requer GPU)
    - ‚úÖ Usa `torch.float32` (CPU-optimizado)
    - ‚ö†Ô∏è Processamento mais lento que GPU
    - üí° Recomendado usar modos Tiny/Small para melhor experi√™ncia

    **Se voc√™ tiver GPU NVIDIA e quiser us√°-la:**
    1. Modifique a linha 75 no c√≥digo: `device = "cuda"`
    2. Descomente o c√≥digo GPU (linhas 82-105)
    3. Instale: `pip install flash-attn --no-build-isolation`
    4. Reinicie a aplica√ß√£o

    ### Depend√™ncias Opcionais

    **Flash Attention 2** (GPU apenas):
    - Melhora significativamente o desempenho em GPU
    - N√£o dispon√≠vel para CPU
    - Opcional - aplica√ß√£o funciona sem ela

    **Instala√ß√£o:**
    ```bash
    pip install flash-attn --no-build-isolation
    ```

    **Requisitos:**
    - GPU NVIDIA com CUDA 11.6+
    - 12GB+ VRAM recomendado
    """)
